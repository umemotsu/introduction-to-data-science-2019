[
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/",
	"title": "データサイエンス概論（2019）",
	"tags": [],
	"description": "",
	"content": " データサイエンス概論（2019） 授業概要 データサイエンスに関する近年の主要な研究成果を取り上げ、基本となる考え方から大規模データへの適用までを体系的に紹介し、具体的な課題に取り組みながら理解を深めさせる。\n達成目標 データサイエンスの基本となる考え方から大規模データへの適用までを体系的に紹介し、具体的な課題に取り組みながら理解を深める。\n担当回  高次元データ  第3回 高次元データを理解する 講義 スライド 添付 slides.pdf (5858 ko) 演習 GitHubリポジトリに、主成分分析、t-SNE、UMAPを用いた高次元データの解析コ\n 潜在変数  第6回 隠れた値を推定する 講義 スライド 添付 slides.pdf (29431 ko) 演習 GitHubリポジトリに、トピックモデルを用いた潜在変数の推定・分析のためのコードが置いて\n "
},
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/latent-variable/lecture/",
	"title": "講義",
	"tags": [],
	"description": "",
	"content": " スライド   添付   slides.pdf  (29431 ko)    演習 GitHubリポジトリに、トピックモデルを用いた潜在変数の推定・分析のためのコードが置いてあります。\nアンケート Googleフォームでフィードバックをください。どんなことでも構いません。\n 内容が簡単すぎた／難しすぎた 説明が雑すぎた／細かすぎた どうでも良い話が多い あそこが分からなかった 次回にあの話をしてほしい …  "
},
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/high-dimensional-data/lecture/",
	"title": "講義",
	"tags": [],
	"description": "",
	"content": " スライド   添付   slides.pdf  (5858 ko)    演習 GitHubリポジトリに、主成分分析、t-SNE、UMAPを用いた高次元データの解析コードが置いてあります。\nアンケート Googleフォームでフィードバックをください。どんなことでも構いません。\n 内容が簡単すぎた／難しすぎた 説明が雑すぎた／細かすぎた どうでも良い話が多い あそこが分からなかった 次回にあの話をしてほしい …  "
},
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/latent-variable/qa/",
	"title": "Q&amp;A",
	"tags": [],
	"description": "",
	"content": " 座学全般 最初の話のスピードが速すぎて追いつくのがつらい すみません。インタラプトがないと早口になりがちなので、追いつけなくなったら止めてください。\n例が豊富で分かりやすかった この講義は概論なので、手法の細部よりも、それがどういう目的が使われるか、どう振る舞うのかを大まかに理解してもらえれば十分なのかと思っています。次回も引き続き、例を多めに説明する予定です。\nトピックモデル トピックモデルのトピック数はどのように決定すればいい？ タスクの種類やデータセットの大きさによって適切なトピック数は異なるので、その値を決定するのは重要な問題です。\n一つの方法として、perplexityと呼ばれる評価指標を使うことができます。Perplexityの定義は次回に説明しますが、直感的にはこの値は予測対象の単語を何候補まで絞り込めるかを表しており、低いほど（この指標において）良いモデルということができます。この指標を用いた場合の手順は、\n 事前にデータセットを訓練用・開発用・テスト用に分割する ハイパーパラメータ（トピック数など）を変えながら訓練データを用いて複数のモデルを学習する 開発用データにおけるperplexityの値が最良となるモデルを選択する。  となります。開発用データを準備せず、訓練用とテスト用の2つに分けて、ハイパーパラメータを決定することもできますが、その場合、テスト用データにオーバーフィッティングする可能性があります。\n別の評価指標として、coherence1と呼ばれるものもあります。Perplexityが汎化能力（未知データに対する予測性能）を測るのに対して、coherenceは学習された各トピックにおける頻出単語の一貫性を所与の単語間類似度関数を用いて評価します。これも次回に簡単に紹介しますが、Wikipediaから学習した自己相互情報量（Pointwise Mutual Information; PMI）を単語間類似度として用いる方法が、人手による判定結果との相関が最も高いと報告されています。\nLDAによる学習結果を別のタスクに利用する場合は、そのタスクにおける性能をモデルの良さとして評価できます。例えば、文書のカテゴリ分類という問題に対して、LDAによって学習したトピック分布を各文書の特徴ベクトルとして、SVMなどの分類モデルを学習することが1つのアプローチとして考えられます。この場合は、perplexityの時と同様に、開発 or テスト用の文書集合を用意して、それらに対する分類精度を比較することで、当該問題に最適なLDAモデルのトピック数を決定することができます。\nより発展的な話題として、学習時にはトピック数を設定せず、データから最適な値を自動で学習するという方法も研究されています。このような「無限次元空間における統計モデル」（これは厳密な説明ではないかもしれません）はノンパラメトリックベイズモデルと呼ばれます。既存のトピックを割り当てるか、新規にトピックを作るかを決める方法の一つとして、中華料理店過程（Chinese Restaurant Process; CRP）と呼ばれる確率過程が存在します。ノンパラメトリックベイズに興味のある人は、この本が参考になるかもしれません。\n確率的投薬モデル トピックモデルにおけるトピックは、このモデルでは疾患に対応している？ そうです。より正確に言うと、このモデルの潜在変数である$z_{rl}$は、$r$番目のレセプトにおいて$l$番目に処方された医薬品$m_{rl}$の対象が、当該レセプトにおいて診断された全疾患$\\{d_{rn}\\}_{n=1}^{N_{r}}$のうち、どれに対応するかを表しています。\nグラフィカルモデル中の$d_{rn}$と$N_{r}$は何を意味している？ それぞれ以下のとおりです。\n $d_{rn}$: $r$番目のレセプトにおいて$n$番目に診断された疾患 $N_{r}$: $r$番目のレセプトにおいて診断された疾患の数  演習全般 コードが分からなくても簡単に理解できる 座学で説明した手法を実際に適用したらどうなるかを分かってもらうのが演習の大事な目標の1つなので、次回も適用事例のノートブックを1つは準備したいと思います。\n各自で作業する感じの方が楽しいかも 特にプログラミングに慣れている人にとってはこういうニーズもあると思いますので、次回は手を動かしてもらう課題も用意しようかと思います。\n David Newman, Jey Han Lau, Karl Grieser, and Timothy Baldwin. 2010. Automatic evaluation of topic coherence. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (HLT \u0026lsquo;10). Association for Computational Linguistics, Stroudsburg, PA, USA, 100-108. [return]   "
},
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/high-dimensional-data/qa/",
	"title": "Q&amp;A",
	"tags": [],
	"description": "",
	"content": " 主成分分析について 説明が速くて、P17の数式が追えなかった。 次回の講義で簡単におさらいと補足をします。\n「特徴量が正規分布に従う」という仮定が存在する？ 正規分布に従っていないデータでも計算は可能ですが、うまく分解ができないこともあります。これも次回に補足します。\nこんな話が聞きたい 情報検索（Information Retrieval; IR）に関する話題 ところどころに混ぜたいと思います。\n（統計的？）因果推論 私もよく分かっていません。この本を読んで勉強しています。\nちなみに、IRの最近の研究の1つに、反事実的推論を用いて位置バイアスを含むクリックログからバイアスのないランキングを学習するというものがあります。1\n勾配ブースティング これも詳しく知りません。興味のある人はこのあたりを眺めてみると良いかもしれません。\nちなみに、IR分野でも少し前までは、ランキング学習手法といえば勾配ブースティングに基づくLambdaMARTという印象でした。2\nKaggleで使える実践的なテクニック 参加したことないのでよく分かりません。ただ、上記の勾配ブースティングがよく使われるイメージはあります。\n現場で起きた話 現場というわけではないですが、データ解析に関する実体験を次回に少し紹介します。\nデータサイエンス お薦めのサイトや書籍 あまり読まないのでよく知りません。方法論を知りたいのであれば、機械学習・統計・データマイニング・データベースなどの良書や解説サイトは豊富にあるので、それらを見てみるのも良いかと思います。\nあとは、Kaggleのコンペに参加したり、企業インターンシップに行ったりして、あるいは自分の研究を通じて、実データにたくさん触れるのが大事だと思います。\n便利なツール 粗いレベルで言えば、Python＋定番の汎用ライブラリ＋対象タスクに特化したライブラリという組み合わせ？\nこれをすべし 上にも書いたように、実データにたくさん触れること。学んだ手法を適用するのも良いけど、高い精度を得ることだけを目的とするのでなく、その背後で何が起きているのか等をよく考えること。関連する話として、国際会議SIGMOD2019のキーノート「Responsible Data Science 」を次回の講義で少し紹介します。\n Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased Learning-to-Rank with Biased Feedback. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (WSDM \u0026lsquo;17). ACM, New York, NY, USA, 781-789. DOI: https://doi.org/10.1145/3018661.3018699 [return] Chris J.C. Burges. 2010. From RankNet to LambdaRank to LambdaMART: An Overview. Microsoft Research Technical Report MSR-TR-2010-82. URL: https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/ [return]   "
},
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/high-dimensional-data/",
	"title": "高次元データ",
	"tags": [],
	"description": "",
	"content": " 第3回 高次元データを理解する  講義  スライド 添付 slides.pdf (5858 ko) 演習 GitHubリポジトリに、主成分分析、t-SNE、UMAPを用いた高次元データの解析コードが置いてあります。 アンケート\n Q\u0026amp;A  主成分分析について 説明が速くて、P17の数式が追えなかった。 次回の講義で簡単におさらいと補足をします。 「特徴量が正規分布に従う」という仮定が\n "
},
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/latent-variable/",
	"title": "潜在変数",
	"tags": [],
	"description": "",
	"content": " 第6回 隠れた値を推定する  講義  スライド 添付 slides.pdf (29431 ko) 演習 GitHubリポジトリに、トピックモデルを用いた潜在変数の推定・分析のためのコードが置いてあります。 アンケート Goog\n Q\u0026amp;A  座学全般 最初の話のスピードが速すぎて追いつくのがつらい すみません。インタラプトがないと早口になりがちなので、追いつけなくなったら止めてくださ\n "
},
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://umemotsu.github.io/introduction-to-data-science-2019/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]